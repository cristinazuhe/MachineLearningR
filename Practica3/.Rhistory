library(randomForest)
library(MASS)
library("glmnet")
set.seed(2121)
#mediana_crim = median(Boston$crim)
#Boston_crim01 = data.frame(Boston, crim01=sign(Boston[,"crim"] - mediana_crim))
indices_train = sample(nrow(Boston), 8*nrow(Boston)%/%10, replace=FALSE)
Boston_train = Boston[indices_train,]
Boston_test = Boston[-indices_train,]
Boston_sinCrim = model.matrix(crim~.-crim, data=Boston_train)[,-1]
Boston_solocrim = as.matrix(Boston_train[,1])
cv.lasso = cv.glmnet(x = Boston_sinCrim, y = Boston_solocrim, alpha=1)
lasso = glmnet(x = Boston_sinCrim, y = Boston_solocrim, alpha=1)
lasso.coef = predict(lasso, type = "coefficients", s = cv.lasso$lambda.min)[1:14,]
lasso.coef
umbral = 0.5
predictoras_umbral <- lasso.coef[abs(lasso.coef) > umbral ]
predictoras_umbral
seleccionadas = names(predictoras_umbral[2:length(predictoras_umbral)])
rr = glmnet(x = as.matrix(Boston_train[,c(seleccionadas)]), y = Boston_solocrim, alpha=0)
ridge.pred <- predict(rr, newx = as.matrix(Boston_test[,c(seleccionadas)]),
s=cv.lasso$lambda.min, type = "response")
error <- mean((ridge.pred - Boston_test[,1])^2)
errro2 = mean((abs(ridge.pred - Boston_test[,1])))
library(randomForest)
library(MASS)
library("glmnet")
set.seed(2)
#mediana_crim = median(Boston$crim)
#Boston_crim01 = data.frame(Boston, crim01=sign(Boston[,"crim"] - mediana_crim))
indices_train = sample(nrow(Boston), 8*nrow(Boston)%/%10, replace=FALSE)
Boston_train = Boston[indices_train,]
Boston_test = Boston[-indices_train,]
Boston_sinCrim = model.matrix(crim~.-crim, data=Boston_train)[,-1]
Boston_solocrim = as.matrix(Boston_train[,1])
cv.lasso = cv.glmnet(x = Boston_sinCrim, y = Boston_solocrim, alpha=1)
lasso = glmnet(x = Boston_sinCrim, y = Boston_solocrim, alpha=1)
lasso.coef = predict(lasso, type = "coefficients", s = cv.lasso$lambda.min)[1:14,]
lasso.coef
umbral = 0.5
predictoras_umbral <- lasso.coef[abs(lasso.coef) > umbral ]
predictoras_umbral
seleccionadas = names(predictoras_umbral[2:length(predictoras_umbral)])
rr = glmnet(x = as.matrix(Boston_train[,c(seleccionadas)]), y = Boston_solocrim, alpha=0)
ridge.pred <- predict(rr, newx = as.matrix(Boston_test[,c(seleccionadas)]),
s=cv.lasso$lambda.min, type = "response")
error <- mean((ridge.pred - Boston_test[,1])^2)
errro2 = mean((abs(ridge.pred - Boston_test[,1])))
library(randomForest)
library(MASS)
library("glmnet")
set.seed(2)
#mediana_crim = median(Boston$crim)
#Boston_crim01 = data.frame(Boston, crim01=sign(Boston[,"crim"] - mediana_crim))
indices_train = sample(nrow(Boston), 8*nrow(Boston)%/%10, replace=FALSE)
Boston_train = Boston[indices_train,]
Boston_test = Boston[-indices_train,]
Boston_sinCrim = model.matrix(crim~.-crim, data=Boston_train)[,-1]
Boston_solocrim = as.matrix(Boston_train[,1])
cv.lasso = cv.glmnet(x = Boston_sinCrim, y = Boston_solocrim, alpha=1)
lasso = glmnet(x = Boston_sinCrim, y = Boston_solocrim, alpha=1)
lasso.coef = predict(lasso, type = "coefficients", s = cv.lasso$lambda.min)[1:14,]
lasso.coef
umbral = 0.5
predictoras_umbral <- lasso.coef[abs(lasso.coef) > umbral ]
predictoras_umbral
seleccionadas = names(predictoras_umbral[2:length(predictoras_umbral)])
rr = glmnet(x = as.matrix(Boston_train[,c(seleccionadas)]), y = Boston_solocrim, alpha=0)
ridge.pred <- predict(rr, newx = as.matrix(Boston_test[,c(seleccionadas)]),
s=cv.lasso$lambda.min, type = "response")
error <- mean((ridge.pred - Boston_test[,1])^2)
errro2 = mean((abs(ridge.pred - Boston_test[,1])))
set.seed(2)
library("e1071")
mediana_crim = median(Boston$crim)
Boston_test_crim01 = data.frame(Boston_test,
crim01=sign(Boston[,"crim"] - mediana_crim))
library(randomForest)
library(MASS)
library("glmnet")
set.seed(2)
#mediana_crim = median(Boston$crim)
#Boston_crim01 = data.frame(Boston, crim01=sign(Boston[,"crim"] - mediana_crim))
indices_train = sample(nrow(Boston), 8*nrow(Boston)%/%10, replace=FALSE)
Boston_train = Boston[indices_train,]
Boston_test = Boston[-indices_train,]
Boston_sinCrim = model.matrix(crim~.-crim, data=Boston_train)[,-1]
Boston_solocrim = as.matrix(Boston_train[,1])
cv.lasso = cv.glmnet(x = Boston_sinCrim, y = Boston_solocrim, alpha=1)
lasso = glmnet(x = Boston_sinCrim, y = Boston_solocrim, alpha=1)
lasso.coef = predict(lasso, type = "coefficients", s = cv.lasso$lambda.min)[1:14,]
lasso.coef
umbral = 0.5
predictoras_umbral <- lasso.coef[abs(lasso.coef) > umbral ]
predictoras_umbral
seleccionadas = names(predictoras_umbral[2:length(predictoras_umbral)])
rr = glmnet(x = as.matrix(Boston_train[,c(seleccionadas)]), y = Boston_solocrim, alpha=0)
ridge.pred <- predict(rr, newx = as.matrix(Boston_test[,c(seleccionadas)]),
s=cv.lasso$lambda.min, type = "response")
error <- mean((ridge.pred - Boston_test[,1])^2)
errro2 = mean((abs(ridge.pred - Boston_test[,1])))
set.seed(2)
library("e1071")
mediana_crim = median(Boston$crim)
Boston_crim01 = data.frame(Boston, crim01=sign(Boston[,"crim"] - mediana_crim))
Boston_train_crim01 = Boston_crim01[indices_train,]
Boston_test_crim01 =  Boston_crim01[-indices_train,]
BostonSVM <- svm(crim01~., data=Boston_train_crim01, kernel="linear",
cost=1, scale = FALSE)
crime.pred <- predict(BostonSVM, Boston_train_crim01)
crime.pred.class <- 2*(crime.pred > 0)-1
matriz = table(predict=crime.pred.class, truth=Boston_train_crim01$crim01)
error = ((matriz[1,2] + matriz[2,1])/sum(matriz))
print(error)
```
Obtenemos un error de 0.1825.
library(randomForest)
library(MASS)
library("glmnet")
set.seed(2)
#mediana_crim = median(Boston$crim)
#Boston_crim01 = data.frame(Boston, crim01=sign(Boston[,"crim"] - mediana_crim))
indices_train = sample(nrow(Boston), 8*nrow(Boston)%/%10, replace=FALSE)
Boston_train = Boston[indices_train,]
Boston_test = Boston[-indices_train,]
Boston_sinCrim = model.matrix(crim~.-crim, data=Boston_train)[,-1]
Boston_solocrim = as.matrix(Boston_train[,1])
cv.lasso = cv.glmnet(x = Boston_sinCrim, y = Boston_solocrim, alpha=1)
lasso = glmnet(x = Boston_sinCrim, y = Boston_solocrim, alpha=1)
lasso.coef = predict(lasso, type = "coefficients", s = cv.lasso$lambda.min)[1:14,]
lasso.coef
umbral = 0.5
predictoras_umbral <- lasso.coef[abs(lasso.coef) > umbral ]
predictoras_umbral
seleccionadas = names(predictoras_umbral[2:length(predictoras_umbral)])
rr = glmnet(x = as.matrix(Boston_train[,c(seleccionadas)]), y = Boston_solocrim, alpha=0)
ridge.pred <- predict(rr, newx = as.matrix(Boston_test[,c(seleccionadas)]),
s=cv.lasso$lambda.min, type = "response")
error <- mean((ridge.pred - Boston_test[,1])^2)
error2 = mean((abs(ridge.pred - Boston_test[,1])))
print(error)
print(error2)
#Cargamos la BD Auto
library(ISLR)
attach(Auto)
f = nrow(Auto)
a = round(f*0.8)
train.index=sample(f, a, replace=FALSE)
train = Auto[train.index, ]
test = Auto[-train.index, ]
mpg01 = rep(0, nrow(Auto))
mpg01[mpg > median(mpg)] = 1
Auto2 = data.frame(Auto, mpg01)
Datos.train = Auto2[train.index, ]
Datos.test = Auto2[-train.index, ]
mpg01.test = mpg01[-train.index]
modelo = glm(mpg01~cylinders+weight+displacement+horsepower, data=Auto2, family="binomial", subset=train.index)
pr = predict(modelo, Datos.test, type="response")
prediccion.glm = rep(-1, length(pr))
prediccion.glm[pr > 0.5] = 1
mpg_11 = rep(-1, nrow(Auto))
mpg_11[mpg > median(mpg)] = 1
mpg_11.test = mpg_11[-train.index]
table(prediccion.glm, mpg_11.test)
mean(prediccion.glm != mpg_11.test)
library(class)
train.knn = cbind(cylinders, weight, displacement, horsepower)[train.index, ]
test.knn = cbind(cylinders, weight, displacement, horsepower)[-train.index, ]
mpg01.train = mpg01[train.index]
vector.knn = vector()
for (k in 1:100){
modelo = knn(train.knn, test.knn, mpg01.train, k=k)
vector.knn = append(vector.knn,mean(modelo != mpg01.test))
}
M = matrix(vector.knn,nrow=1,ncol=length(vector.knn),dimnames=list(c("Acierto"), paste("K=", c(1:length(vector.knn)))))
k.optimo = which.min(M)
paste("K test = ",k.optimo)
modelo = knn(train.knn, test.knn, mpg01.train, k=k.optimo)
table(modelo, mpg01.test)
mean(modelo != mpg01.test)
particiones = 5
corte = round(f/particiones)
vector.cv.glm = vector()
for(p in 0:(particiones-1)){
test.index.cv.glm = ((p*corte)+1):(corte*(p+1))
mpg01.test = mpg01[test.index.cv.glm]
Datos.test = Auto2[test.index.cv.glm,]
Datos.train = Auto2[-test.index.cv.glm,]
modelo = glm(mpg01~cylinders+weight+displacement+horsepower, data=Datos.train, family="binomial")
pr = predict(modelo, Datos.test, type="response")
predictor = rep(0, length(pr))
predictor[pr > 0.5] = 1
vector.cv.glm = append(vector.cv.glm, mean(predictor != mpg01.test))
}
paste("Error Medio: ", mean(vector.cv.glm)*100, "%")
vector.cv.knn = rep(0, 100)
vector.knn = rep(0, particiones)
library(ISLR)
Predictoras = cbind(Auto$mpg, Auto$displacement, Auto$horsepower, Auto$weight, Auto$year)
colnames(Predictoras) = c("mpg", "displacement", "horsepower", "weight", "year")
set.seed(2)
indices_test = sample(nrow(Predictoras), 2*nrow(Predictoras)%/%10, replace=FALSE)
Predictoras_test = Predictoras[indices_test,]
Predictoras_train = Predictoras[-indices_test,]
mediana_mpg = median(Auto$mpg)
Predictoras_mpg01 = data.frame(Predictoras,
mpg01 = sign(Predictoras[,"mpg"] - mediana_mpg))
Predictoras_train_mpg01 = Predictoras_mpg01[-indices_test,]
Predictoras_test_mpg01 = Predictoras_mpg01[indices_test,]
for(i in 1:nrow(Predictoras_test_mpg01)){
if((Predictoras_test_mpg01[i,"mpg01"]) == -1)
Predictoras_test_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_train_mpg01)){
if((Predictoras_train_mpg01[i,"mpg01"]) == -1)
Predictoras_train_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_mpg01)){
if((Predictoras_mpg01[i,"mpg01"]) == -1)
Predictoras_mpg01[i,"mpg01"] = 0
}
ajuste_rlog <- glm(mpg01 ~ displacement + horsepower + weight + year,
data= Predictoras_train_mpg01, family="binomial")
probabilidades = predict(ajuste_rlog, Predictoras_test_mpg01, type="response")
probabilidades01 = rep(1,dim(Predictoras_test_mpg01)[1])
probabilidades01[probabilidades<0.5] = 0
matriz_confusion = table(probabilidades01, Predictoras_test_mpg01$mpg01)
print(matriz_confusion)
error = (matriz_confusion[1,2] + matriz_confusion[2,1])/sum(matriz_confusion)
print(error)
library(ISLR)
Predictoras = cbind(Auto$mpg, Auto$displacement, Auto$horsepower, Auto$weight, Auto$year)
colnames(Predictoras) = c("mpg", "displacement", "horsepower", "weight", "year")
set.seed(2)
indices_test = sample(nrow(Predictoras), 2*nrow(Predictoras)%/%10, replace=FALSE)
Predictoras_test = Predictoras[indices_test,]
Predictoras_train = Predictoras[-indices_test,]
mediana_mpg = median(Auto$mpg)
Predictoras_mpg01 = data.frame(Predictoras,
mpg01 = sign(Predictoras[,"mpg"] - mediana_mpg))
Predictoras_train_mpg01 = Predictoras_mpg01[-indices_test,]
Predictoras_test_mpg01 = Predictoras_mpg01[indices_test,]
for(i in 1:nrow(Predictoras_test_mpg01)){
if((Predictoras_test_mpg01[i,"mpg01"]) == -1)
Predictoras_test_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_train_mpg01)){
if((Predictoras_train_mpg01[i,"mpg01"]) == -1)
Predictoras_train_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_mpg01)){
if((Predictoras_mpg01[i,"mpg01"]) == -1)
Predictoras_mpg01[i,"mpg01"] = 0
}
ajuste_rlog <- glm(mpg01 ~ displacement + horsepower + weight + year,
data= Predictoras_train_mpg01, family="binomial")
probabilidades = predict(ajuste_rlog, Predictoras_test_mpg01, type="response")
probabilidades01 = rep(1,dim(Predictoras_test_mpg01)[1])
probabilidades01[probabilidades<0.5] = 0
matriz_confusion = table(probabilidades01, Predictoras_test_mpg01$mpg01)
print(matriz_confusion)
error = (matriz_confusion[1,2] + matriz_confusion[2,1])/sum(matriz_confusion)
print(error)
library(class)
library(e1071)
set.seed(2)
columnas=  dim(Predictoras_train_mpg01)[2]
datos_normalizados = scale(rbind(Predictoras_test_mpg01[,-columnas],
Predictoras_train_mpg01[,-columnas]))
test_normalizada = datos_normalizados[1:dim(Predictoras_test_mpg01)[1],]
train_normalizada = datos_normalizados[(dim(Predictoras_test_mpg01)[1] +1):
dim(datos_normalizados)[1],]
mpg01_train = Predictoras_train_mpg01[,columnas]
mpg01_test = Predictoras_test_mpg01[,columnas]
mpg01_ambos = c(mpg01_train, mpg01_test)
mpg01_train = Predictoras_train_mpg01[,columnas]
mpg01_test = Predictoras_test_mpg01[,columnas]
mpg01_ambos = c(mpg01_train, mpg01_test)
posibles_k <- tune.knn(datos_normalizados, as.factor(mpg01_ambos), k=1:10,
tune_control = tune.control(sampling = "cross"))
summary(posibles_k)
predicciones = knn(train_normalizada, test_normalizada, mpg01_train, k=4)
matriz_confusion_knn = table(predicciones, mpg01_test)
print(matriz_confusion_knn)
errorknn = ((matriz_confusion_knn[1,2] + matriz_confusion_knn[2,1])/sum(matriz_confusion_knn))
print(errorknn)
predicciones
predicciones$prob
predicciones = knn(train_normalizada, test_normalizada, mpg01_train, k=4, prob=T)
matriz_confusion_knn = table(predicciones, mpg01_test)
print(matriz_confusion_knn)
errorknn = ((matriz_confusion_knn[1,2] + matriz_confusion_knn[2,1])/sum(matriz_confusion_knn))
print(errorknn)
predicciones$prob
attr(predicciones, "prob")
probabilidades01
if(probabilidades01 ==0) nuevo =0
if(probabilidades01==0)
nuevo = 1
probabilidades01[1]
probabilidades01[]
probabilidades01[]==0
probabilidades01[]==0 then nuevo[]=1
probabilidades01[]==0 then nuevo=0
if(probabilidades01[]==0) then nuevo=1
if(probabilidades01[]==0)  nuevo=1
prob
prob = attr(predicciones, "prob")
library(ROCR)
rocplot=function(pred, truth, ...){ #pag 365
predob = prediction (pred, truth)
perf = performance (predob, "tpr", "fpr")
plot(perf, ...)
}
rocplot(probabilidades01, Predictoras_test_mpg01$mpg01)
rocplot(as.numeric(predicciones), mpg01_test)
prob = attr(predicciones, "prob")
prob
if(probabilidades01==0)
then nueov=1
probabilidades01
probabilidades01[]==0
predicciones = knn(train_normalizada, test_normalizada, mpg01_train, k=4, prob=T)
prob = attr(predicciones, "prob")
matriz_confusion_knn = table(predicciones, mpg01_test)
print(matriz_confusion_knn)
errorknn = ((matriz_confusion_knn[1,2] + matriz_confusion_knn[2,1])/sum(matriz_confusion_knn))
print(errorknn)
predicciones
prob
predicciones
library(ISLR)
Predictoras = cbind(Auto$mpg, Auto$displacement, Auto$horsepower, Auto$weight, Auto$year)
colnames(Predictoras) = c("mpg", "displacement", "horsepower", "weight", "year")
set.seed(2)
indices_test = sample(nrow(Predictoras), 2*nrow(Predictoras)%/%10, replace=FALSE)
Predictoras_test = Predictoras[indices_test,]
Predictoras_train = Predictoras[-indices_test,]
mediana_mpg = median(Auto$mpg)
Predictoras_mpg01 = data.frame(Predictoras,
mpg01 = sign(Predictoras[,"mpg"] - mediana_mpg))
Predictoras_train_mpg01 = Predictoras_mpg01[-indices_test,]
Predictoras_test_mpg01 = Predictoras_mpg01[indices_test,]
for(i in 1:nrow(Predictoras_test_mpg01)){
if((Predictoras_test_mpg01[i,"mpg01"]) == -1)
Predictoras_test_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_train_mpg01)){
if((Predictoras_train_mpg01[i,"mpg01"]) == -1)
Predictoras_train_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_mpg01)){
if((Predictoras_mpg01[i,"mpg01"]) == -1)
Predictoras_mpg01[i,"mpg01"] = 0
}
ajuste_rlog <- glm(mpg01 ~ displacement + horsepower + weight + year,
data= Predictoras_train_mpg01, family="binomial")
probabilidades = predict(ajuste_rlog, Predictoras_test_mpg01, type="response")
probabilidades01 = rep(1,dim(Predictoras_test_mpg01)[1])
probabilidades01[probabilidades<0.5] = 0
matriz_confusion = table(probabilidades01, Predictoras_test_mpg01$mpg01)
print(matriz_confusion)
error = (matriz_confusion[1,2] + matriz_confusion[2,1])/sum(matriz_confusion)
print(error)
library(class)
library(e1071)
set.seed(2)
columnas=  dim(Predictoras_train_mpg01)[2]
datos_normalizados = scale(rbind(Predictoras_test_mpg01[,-columnas],
Predictoras_train_mpg01[,-columnas]))
test_normalizada = datos_normalizados[1:dim(Predictoras_test_mpg01)[1],]
train_normalizada = datos_normalizados[(dim(Predictoras_test_mpg01)[1] +1):
dim(datos_normalizados)[1],]
mpg01_train = Predictoras_train_mpg01[,columnas]
mpg01_test = Predictoras_test_mpg01[,columnas]
mpg01_ambos = c(mpg01_train, mpg01_test)
posibles_k <- tune.knn(datos_normalizados, as.factor(mpg01_ambos), k=1:10,
tune_control = tune.control(sampling = "cross"))
summary(posibles_k)
predicciones = knn(train_normalizada, test_normalizada, mpg01_train, k=4)
matriz_confusion_knn = table(predicciones, mpg01_test)
print(matriz_confusion_knn)
errorknn = ((matriz_confusion_knn[1,2] + matriz_confusion_knn[2,1])/sum(matriz_confusion_knn))
print(errorknn)
predicciones
predicciones = knn(train_normalizada, test_normalizada, mpg01_train, k=4, prob=T)
prob = attr(predicciones, "prob")
matriz_confusion_knn = table(predicciones, mpg01_test)
print(matriz_confusion_knn)
errorknn = ((matriz_confusion_knn[1,2] + matriz_confusion_knn[2,1])/sum(matriz_confusion_knn))
print(errorknn)
predicciones
nuevas = ifelse(predicciones == "0"), 1-prob, prob)
nuevas = ifelse(predicciones == "0", 1-prob, prob)
nuevas
nuevas = ifelse(predicciones == "0", 1-prob, prob)
library(ROCR)
rocplot=function(pred, truth, ...){ #pag 365
predob = prediction (pred, truth)
perf = performance (predob, "tpr", "fpr")
plot(perf, ...)
}
rocplot(nuevas, Predictoras_test_mpg01$mpg01) #knn
rocplot(as.numeric(predicciones), mpg01_test)
probabilidades01
probabilidades = predict(ajuste_rlog, Predictoras_test_mpg01, type="response", prob=T)
probabilidades01 = rep(1,dim(Predictoras_test_mpg01)[1])
probabilidades01[probabilidades<0.5] = 0
probrl = attr(probabilidades01, "prob")
probrl
probabilidades
predicciones
probabilidades01
probabilidades
nuevas = ifelse(probabilidades01 == "0", 1-probabilidades, probabilidades)
neuvas
nuevas
nuevasknn = ifelse(predicciones == "0", 1-prob, prob)
nuevas = ifelse(probabilidades01 == "0", 1-probabilidades, probabilidades)
library(ROCR)
rocplot=function(pred, truth, ...){ #pag 365
predob = prediction (pred, truth)
perf = performance (predob, "tpr", "fpr")
plot(perf, ...)
}
rocplot(nuevas, Predictoras_test_mpg01$mpg01)
rocplot(nuevasknn, mpg01_test) #knn
nuevas
nuevasknn
nuevasknn = ifelse(predicciones == "0", 1-prob, prob)
nuevas = ifelse(probabilidades01 == "0", 1-probabilidades, probabilidades)
library(ROCR)
rocplot=function(pred, truth, ...){ #pag 365
predob = prediction (pred, truth)
perf = performance (predob, "tpr", "fpr")
plot(perf, ...)
}
rocplot(probabilidades01, Predictoras_test_mpg01$mpg01)
rocplot(nuevasknn, mpg01_test) #knn
probabilidades01
probabilidades
library(ISLR)
Predictoras = cbind(Auto$mpg, Auto$displacement, Auto$horsepower, Auto$weight, Auto$year)
colnames(Predictoras) = c("mpg", "displacement", "horsepower", "weight", "year")
set.seed(2)
indices_test = sample(nrow(Predictoras), 2*nrow(Predictoras)%/%10, replace=FALSE)
Predictoras_test = Predictoras[indices_test,]
Predictoras_train = Predictoras[-indices_test,]
mediana_mpg = median(Auto$mpg)
Predictoras_mpg01 = data.frame(Predictoras,
mpg01 = sign(Predictoras[,"mpg"] - mediana_mpg))
Predictoras_train_mpg01 = Predictoras_mpg01[-indices_test,]
Predictoras_test_mpg01 = Predictoras_mpg01[indices_test,]
for(i in 1:nrow(Predictoras_test_mpg01)){
if((Predictoras_test_mpg01[i,"mpg01"]) == -1)
Predictoras_test_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_train_mpg01)){
if((Predictoras_train_mpg01[i,"mpg01"]) == -1)
Predictoras_train_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_mpg01)){
if((Predictoras_mpg01[i,"mpg01"]) == -1)
Predictoras_mpg01[i,"mpg01"] = 0
}
ajuste_rlog <- glm(mpg01 ~ displacement + horsepower + weight + year,
data= Predictoras_train_mpg01, family="binomial")
probabilidades = predict(ajuste_rlog, Predictoras_test_mpg01, type="response")
probabilidades01 = rep(1,dim(Predictoras_test_mpg01)[1])
probabilidades01[probabilidades<0.5] = 0
matriz_confusion = table(probabilidades01, Predictoras_test_mpg01$mpg01)
print(matriz_confusion)
error = (matriz_confusion[1,2] + matriz_confusion[2,1])/sum(matriz_confusion)
print(error)
library(class)
library(e1071)
set.seed(2)
columnas=  dim(Predictoras_train_mpg01)[2]
datos_normalizados = scale(rbind(Predictoras_test_mpg01[,-columnas],
Predictoras_train_mpg01[,-columnas]))
test_normalizada = datos_normalizados[1:dim(Predictoras_test_mpg01)[1],]
train_normalizada = datos_normalizados[(dim(Predictoras_test_mpg01)[1] +1):
dim(datos_normalizados)[1],]
mpg01_train = Predictoras_train_mpg01[,columnas]
mpg01_test = Predictoras_test_mpg01[,columnas]
mpg01_ambos = c(mpg01_train, mpg01_test)
posibles_k <- tune.knn(datos_normalizados, as.factor(mpg01_ambos), k=1:10,
tune_control = tune.control(sampling = "cross"))
summary(posibles_k)
predicciones = knn(train_normalizada, test_normalizada, mpg01_train, k=4)
matriz_confusion_knn = table(predicciones, mpg01_test)
print(matriz_confusion_knn)
errorknn = ((matriz_confusion_knn[1,2] + matriz_confusion_knn[2,1])/sum(matriz_confusion_knn))
print(errorknn)
particiones = 5
tope = round((nrow(Predictoras))/particiones)
vector_errores = vector()
for(i in 0:(particiones-1)){
test.index_aux = ((i*tope)+1):(tope*(i+1))
mpg01.test_aux = mpg01_ambos[test.index_aux]
Predictoras_test_aux = Predictoras_mpg01[test.index_aux,]
Predictoras_train_aux = Predictoras_mpg01[-test.index_aux,]
ajuste_rlog <- glm(mpg01 ~ displacement + horsepower + weight + year,
data= Predictoras_train_aux, family="binomial")
probabilidades = predict(ajuste_rlog, Predictoras_test_aux, type="response")
probabilidades01 = rep(1,length(probabilidades))
probabilidades01[probabilidades<0.5] = 0
m_confusion_aux = table(probabilidades01, Predictoras_test_aux$mpg01)
error_aux = (m_confusion_aux[1,2] + m_confusion_aux[2,1])/sum(m_confusion_aux)
vector_errores = append(vector_errores, error_aux)
}
paste("Error medio en regresión logística: ", mean(vector_errores)*100, "%")
