selected <- lasso.coef[abs(lasso.coef) > 0.1 ]
selected
set.seed(13)
nameSelected <- names(selected[2:length(selected)])
ridge.model <- glmnet(x = as.matrix(Boston[,nameSelected]), y = matrix(Boston[,1]), alpha = 0, standardize = FALSE)
ridge.pred <- predict(ridge.model, newx = as.matrix(Boston[,nameSelected]), s=bestLambda, type = "response")
error <- mean((ridge.pred - Boston[,1])^2)
error
set.seed(13)
library("e1071")
umbral <- median(Boston$crim)
XCrim <- 2*(Boston$crim > umbral)-1
XCrim
#Sustituimos crim por la nueva columna
XBoston <- cbind(XCrim, Boston[,-1])
XBostonSVM <- svm(XCrim~., data=XBoston, kernel="linear", cost=0.1, scale = FALSE)
#XBostonSVM2 <- svm(XCrim~., data=XBoston, kernel="radial", cost=10, scale = FALSE)
crime.pred <- predict(XBostonSVM, XBoston)
crime.pred.class <- 2*(crime.pred > 0)-1
matriz = table(predict=crime.pred.class, truth=XBoston$XCrim)
error = ((matriz[1,2] + matriz[2,1])/sum(matriz))
print(error)
crime.pred2 <- predict(XBostonSVM2, XBoston)
crime.pred.class2 <- 2*(crime.pred2 > 0)-1
table(predict=crime.pred.class2, truth=XBoston$XCrim)
crime.pred <- predict(XBostonSVM, XBoston)
crime.pred.class <- 2*(crime.pred > 0)-1
matriz = table(predict=crime.pred.class, truth=XBoston$XCrim)
error = ((matriz[1,2] + matriz[2,1])/sum(matriz))
print(error)
#crime.pred2 <- predict(XBostonSVM2, XBoston)
#crime.pred.class2 <- 2*(crime.pred2 > 0)-1
#table(predict=crime.pred.class2, truth=XBoston$XCrim)
rr = glmnet(x = as.matrix(Boston_train_crim01[,c(seleccionadas)]), y = Boston_solocrim, alpha=0)
ridge.pred <- predict(rr, newx = as.matrix(Boston_test_crim01[,c(seleccionadas)]),
s=cv.lasso$lambda.min, type = "response")
error <- mean((ridge.pred - Boston_test_crim01[,1])^2)
library(randomForest)
library(MASS)
library("glmnet")
set.seed(2)
mediana_crim = median(Boston$crim)
Boston_crim01 = data.frame(Boston, crim01=sign(Boston[,"crim"] - mediana_crim))
indices_train = sample(nrow(Boston_crim01), 8*nrow(Boston_crim01)%/%10, replace=FALSE)
Boston_train_crim01 = Boston_crim01[indices_train,]
Boston_test_crim01 = Boston_crim01[-indices_train,]
Boston_sinCrims = model.matrix(crim~.-crim-crim01, data=Boston_train_crim01)[,-1]
Boston_solocrim = as.matrix(Boston_train_crim01[,1])
cv.lasso = cv.glmnet(x = Boston_sinCrims, y = Boston_solocrim, alpha=1)
lasso = glmnet(x = Boston_sinCrims, y = Boston_solocrim, alpha=1)
lasso.coef = predict(lasso, type = "coefficients", s = cv.lasso$lambda.min)[1:14,]
lasso.coef
umbral = 0.1
predictoras_umbral <- lasso.coef[abs(lasso.coef) > umbral ]
predictoras_umbral
seleccionadas = names(predictoras_umbral[2:length(predictoras_umbral)])
rr = glmnet(x = as.matrix(Boston_train_crim01[,c(seleccionadas)]), y = Boston_solocrim, alpha=0)
ridge.pred <- predict(rr, newx = as.matrix(Boston_test_crim01[,c(seleccionadas)]),
s=cv.lasso$lambda.min, type = "response")
error <- mean((ridge.pred - Boston_test_crim01[,1])^2)
set.seed(2)
library("e1071")
BostonSVM <- svm(crim01~., data=Boston_train_crim01, kernel="linear",
cost=0.1, scale = FALSE)
crime.pred <- predict(BostonSVM, Boston_train_crim01)
crime.pred.class <- 2*(crime.pred > 0)-1
matriz = table(predict=crime.pred.class, truth=Boston_train_crim01$crim01)
error = ((matriz[1,2] + matriz[2,1])/sum(matriz))
print(error)
BostonSVM2 <- svm(crim01~., data=Boston_train_crim01, kernel="radial",
cost=10, scale = FALSE)
crime.pred2 <- predict(BostonSVM2, Boston_train_crim01)
crime.pred2.class <- 2*(crime.pred2 > 0)-1
matriz2 = table(predict=crime.pred2.class, truth=Boston_train_crim01$crim01)
error2 = ((matriz2[1,2] + matriz2[2,1])/sum(matriz2))
print(error2)
BostonSVM2 <- svm(crim01~., data=Boston_train_crim01, kernel="radial",
cost=1, scale = FALSE)
crime.pred2 <- predict(BostonSVM2, Boston_train_crim01)
crime.pred2.class <- 2*(crime.pred2 > 0)-1
matriz2 = table(predict=crime.pred2.class, truth=Boston_train_crim01$crim01)
error2 = ((matriz2[1,2] + matriz2[2,1])/sum(matriz2))
print(error2)
BostonSVM2 <- svm(crim01~., data=Boston_train_crim01, kernel="polynomial",
cost=1, scale = FALSE)
crime.pred2 <- predict(BostonSVM2, Boston_train_crim01)
crime.pred2.class <- 2*(crime.pred2 > 0)-1
matriz2 = table(predict=crime.pred2.class, truth=Boston_train_crim01$crim01)
error2 = ((matriz2[1,2] + matriz2[2,1])/sum(matriz2))
print(error2)
BostonSVM2 <- svm(crim01~., data=Boston_train_crim01, kernel="radial",
cost=1, scale = FALSE)
crime.pred2 <- predict(BostonSVM2, Boston_train_crim01)
crime.pred2.class <- 2*(crime.pred2 > 0)-1
matriz2 = table(predict=crime.pred2.class, truth=Boston_train_crim01$crim01)
error2 = ((matriz2[1,2] + matriz2[2,1])/sum(matriz2))
print(error2)
set.seed(2)
library("e1071")
BostonSVM <- svm(crim01~., data=Boston_train_crim01, kernel="linear",
cost=1, scale = FALSE)
crime.pred <- predict(BostonSVM, Boston_train_crim01)
crime.pred.class <- 2*(crime.pred > 0)-1
matriz = table(predict=crime.pred.class, truth=Boston_train_crim01$crim01)
error = ((matriz[1,2] + matriz[2,1])/sum(matriz))
print(error)
BostonSVM2 <- svm(crim01~., data=Boston_train_crim01, kernel="radial",
cost=1, scale = FALSE)
crime.pred2 <- predict(BostonSVM2, Boston_train_crim01)
crime.pred2.class <- 2*(crime.pred2 > 0)-1
matriz2 = table(predict=crime.pred2.class, truth=Boston_train_crim01$crim01)
error2 = ((matriz2[1,2] + matriz2[2,1])/sum(matriz2))
print(error2)
library(MASS)
attach(Boston)
crim01 = rep(0, length(crim))
crim01[crim>median(crim)] = 1
Boston2 = data.frame(Boston, crim01)
set.seed(4)
f = nrow(Boston2)
a = round(f*0.8)
train.index=sample(f, a, replace=FALSE)
library(glmnet)
x = model.matrix(crim~.-crim01, data=Boston2)[,-1]
y = Boston2$crim
cv.lasso = cv.glmnet(x,y,alpha = 1)
out = glmnet(x,y,alpha = 1)
lasso.coef = predict(out, type = "coef", s = cv.lasso$lambda.min)
lasso.coef
x.ridge = model.matrix(crim~zn+chas+nox+dis+rad, data=Boston2)
ridge = glmnet(x.ridge[train.index,], Boston2[train.index,]$crim, alpha = 0)
ridge.pred = predict(ridge, newx = x.ridge[-train.index,])
mean((ridge.pred-y[-train.index])^2)
library(e1071)
set.seed(4)
tune.out = tune(svm, crim01~., data=Boston2[train.index,], kernel="linear", ranges=list(cost=10^seq(-3, 1, by=1)))
summary(tune.out)
tune.out.radial = tune(svm, crim01~., data=Boston2[train.index,], kernel="radial", ranges=list(cost=10^seq(-3, 1, by=1)))
summary(tune.out.radial)
x.ridge = model.matrix(crim~zn+chas+nox+dis+rad, data=Boston2)
ridge = glmnet(x.ridge[train.index,], Boston2[train.index,]$crim, alpha = 0)
ridge.pred = predict(ridge, newx = x.ridge[-train.index,])
mean((ridge.pred-y[-train.index])^2)
library(glmnet)
x = model.matrix(crim~.-crim01, data=Boston2)[,-1]
y = Boston2$crim
cv.lasso = cv.glmnet(x,y,alpha = 1)
out = glmnet(x,y,alpha = 1)
lasso.coef = predict(out, type = "coef", s = cv.lasso$lambda.min)
lasso.coef
crime.pred2
library(randomForest)
library(MASS)
library("glmnet")
set.seed(2)
mediana_crim = median(Boston$crim)
Boston_crim01 = data.frame(Boston, crim01=sign(Boston[,"crim"] - mediana_crim))
indices_train = sample(nrow(Boston_crim01), 8*nrow(Boston_crim01)%/%10, replace=FALSE)
Boston_train_crim01 = Boston_crim01[indices_train,]
Boston_test_crim01 = Boston_crim01[-indices_train,]
Boston_sinCrims = model.matrix(crim~.-crim-crim01, data=Boston_train_crim01)[,-1]
Boston_solocrim = as.matrix(Boston_train_crim01[,1])
cv.lasso = cv.glmnet(x = Boston_sinCrims, y = Boston_solocrim, alpha=1)
lasso = glmnet(x = Boston_sinCrims, y = Boston_solocrim, alpha=1)
lasso.coef = predict(lasso, type = "coefficients", s = cv.lasso$lambda.min)[1:14,]
lasso.coef
umbral = 0.1
predictoras_umbral <- lasso.coef[abs(lasso.coef) > umbral ]
predictoras_umbral
seleccionadas = names(predictoras_umbral[2:length(predictoras_umbral)])
rr = glmnet(x = as.matrix(Boston_train_crim01[,c(seleccionadas)]), y = Boston_solocrim, alpha=0)
ridge.pred <- predict(rr, newx = as.matrix(Boston_test_crim01[,c(seleccionadas)]),
s=cv.lasso$lambda.min, type = "response")
error <- mean((ridge.pred - Boston_test_crim01[,1])^2)
set.seed(2)
library("e1071")
BostonSVM <- svm(crim01~., data=Boston_train_crim01, kernel="linear",
cost=1, scale = FALSE)
crime.pred <- predict(BostonSVM, Boston_train_crim01)
crime.pred.class <- 2*(crime.pred > 0)-1
matriz = table(predict=crime.pred.class, truth=Boston_train_crim01$crim01)
error = ((matriz[1,2] + matriz[2,1])/sum(matriz))
print(error)
BostonSVM2 <- svm(crim01~., data=Boston_train_crim01, kernel="radial",
cost=1, scale = FALSE)
crime.pred2 <- predict(BostonSVM2, Boston_train_crim01)
crime.pred2.class <- 2*(crime.pred2 > 0)-1
matriz2 = table(predict=crime.pred2.class, truth=Boston_train_crim01$crim01)
error2 = ((matriz2[1,2] + matriz2[2,1])/sum(matriz2))
print(error2)
crime.pred2
crime.pred2.class
library(ISLR)
Predictoras = cbind(Auto$mpg, Auto$displacement, Auto$horsepower, Auto$weight, Auto$year)
colnames(Predictoras) = c("mpg", "displacement", "horsepower", "weight", "year")
set.seed(2)
indices_test = sample(nrow(Predictoras), 2*nrow(Predictoras)%/%10, replace=FALSE)
Predictoras_test = Predictoras[indices_test,]
Predictoras_train = Predictoras[-indices_test,]
mediana_mpg = median(Auto$mpg)
Predictoras_train_mpg01 = data.frame(Predictoras_train,
mpg01=sign(Predictoras_train[,"mpg"] - mediana_mpg))
Predictoras_test_mpg01 = data.frame(Predictoras_test,
mpg01=sign(Predictoras_test[,"mpg"] - mediana_mpg))
for(i in 1:nrow(Predictoras_test_mpg01)){
if((Predictoras_test_mpg01[i,"mpg01"]) == -1)
Predictoras_test_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_train_mpg01)){
if((Predictoras_train_mpg01[i,"mpg01"]) == -1)
Predictoras_train_mpg01[i,"mpg01"] = 0
}
ajuste_rlog <- glm(mpg01 ~ displacement + horsepower + weight + year,
data= Predictoras_train_mpg01, family=binomial)
probabilidades = predict(ajuste_rlog, Predictoras_test_mpg01, type="response")
probabilidades01 = rep(1,dim(Predictoras_test_mpg01)[1])
probabilidades01[probabilidades<0.5] = 0
matriz_confusion = table(probabilidades01, Predictoras_test_mpg01$mpg01)
print(matriz_confusion)
error = (matriz_confusion[1,2] + matriz_confusion[2,1])/sum(matriz_confusion)
print(error)
library(class)
library(e1071)
set.seed(2)
columnas=  dim(Predictoras_train_mpg01)[2]
datos_normalizados = scale(rbind(Predictoras_test_mpg01[,-columnas],
Predictoras_train_mpg01[,-columnas]))
test_normalizada = datos_normalizados[1:dim(Predictoras_test_mpg01)[1],]
train_normalizada = datos_normalizados[(dim(Predictoras_test_mpg01)[1] +1):
dim(datos_normalizados)[1],]
mpg01_train = Predictoras_train_mpg01[,columnas]
mpg01_test = Predictoras_test_mpg01[,columnas]
mpg01_ambos = c(mpg01_train, mpg01_test)
posibles_k <- tune.knn(datos_normalizados, as.factor(mpg01_ambos), k=1:10,
tune_control = tune.control(sampling = "cross"))
summary(posibles_k)
predicciones = knn(train_normalizada, test_normalizada, mpg01_train, k=4)
matriz_confusion_knn = table(predicciones, mpg01_test)
print(matriz_confusion_knn)
errorknn = ((matriz_confusion_knn[1,2] + matriz_confusion_knn[2,1])/sum(matriz_confusion_knn))
print(errorknn)
library(ROCR)
rocplot=function(pred, truth, ...){ #pag 365
predob = prediction (pred, truth)
perf = performance (predob, "tpr", "fpr")
plot(perf, ...)
}
rocplot(probabilidades01, Predictoras_test_mpg01$mpg01)
rocplot(as.numeric(predicciones), mpg01_test)
#Cargamos la BD Auto
library(ISLR)
attach(Auto)
f = nrow(Auto)
a = round(f*0.8)
train.index=sample(f, a, replace=FALSE)
train = Auto[train.index, ]
test = Auto[-train.index, ]
mpg01 = rep(0, nrow(Auto))
mpg01[mpg > median(mpg)] = 1
Auto2 = data.frame(Auto, mpg01)
Datos.train = Auto2[train.index, ]
Datos.test = Auto2[-train.index, ]
mpg01.test = mpg01[-train.index]
modelo = glm(mpg01~cylinders+weight+displacement+horsepower, data=Auto2, family="binomial", subset=train.index)
pr = predict(modelo, Datos.test, type="response")
prediccion.glm = rep(-1, length(pr))
prediccion.glm[pr > 0.5] = 1
mpg_11 = rep(-1, nrow(Auto))
mpg_11[mpg > median(mpg)] = 1
mpg_11.test = mpg_11[-train.index]
table(prediccion.glm, mpg_11.test)
mean(prediccion.glm != mpg_11.test)
library(class)
train.knn = cbind(cylinders, weight, displacement, horsepower)[train.index, ]
test.knn = cbind(cylinders, weight, displacement, horsepower)[-train.index, ]
mpg01.train = mpg01[train.index]
vector.knn = vector()
for (k in 1:100){
modelo = knn(train.knn, test.knn, mpg01.train, k=k)
vector.knn = append(vector.knn,mean(modelo != mpg01.test))
}
M = matrix(vector.knn,nrow=1,ncol=length(vector.knn),dimnames=list(c("Acierto"), paste("K=", c(1:length(vector.knn)))))
k.optimo = which.min(M)
paste("K test = ",k.optimo)
modelo = knn(train.knn, test.knn, mpg01.train, k=k.optimo)
table(modelo, mpg01.test)
mean(modelo != mpg01.test)
particiones = 5
corte = round(f/particiones)
vector.cv.glm = vector()
for(p in 0:(particiones-1)){
test.index.cv.glm = ((p*corte)+1):(corte*(p+1))
mpg01.test = mpg01[test.index.cv.glm]
Datos.test = Auto2[test.index.cv.glm,]
Datos.train = Auto2[-test.index.cv.glm,]
modelo = glm(mpg01~cylinders+weight+displacement+horsepower, data=Datos.train, family="binomial")
pr = predict(modelo, Datos.test, type="response")
predictor = rep(0, length(pr))
predictor[pr > 0.5] = 1
vector.cv.glm = append(vector.cv.glm, mean(predictor != mpg01.test))
}
paste("Error Medio: ", mean(vector.cv.glm)*100, "%")
vector.cv.knn = rep(0, 100)
vector.knn = rep(0, particiones)
for (k in 1:100){
for(p in 0:(particiones-1)){
test.index.cv.knn = ((p*corte)+1):(corte*(p+1))
mpg01.test = mpg01[test.index.cv.knn]
mpg01.train = mpg01[-test.index.cv.knn]
Datos.test = cbind(cylinders, weight, displacement, horsepower)[test.index.cv.knn,]
Datos.train = cbind(cylinders, weight, displacement, horsepower)[-test.index.cv.knn,]
modelo = knn(Datos.train, Datos.test, mpg01.train, k=k)
vector.knn[p+1] = mean((modelo != mpg01.test))
}
vector.cv.knn[k] = mean(vector.knn)
}
M = matrix(vector.cv.knn,nrow=1,ncol=length(vector.cv.knn),dimnames=list(c("Acierto"), paste("K=", c(1:length(vector.cv.knn)))))
min = which.min(M)
paste("Error Medio para el menor valor de K en k=",min,":",vector.cv.knn[min])
particiones = 5
corte = round(f/particiones)
vector.cv.glm = vector()
for(p in 0:(particiones-1)){
test.index.cv.glm = ((p*corte)+1):(corte*(p+1))
mpg01.test = mpg01[test.index.cv.glm]
Datos.test = Auto2[test.index.cv.glm,]
Datos.train = Auto2[-test.index.cv.glm,]
modelo = glm(mpg01~cylinders+weight+displacement+horsepower, data=Datos.train,
family="binomial")
pr = predict(modelo, Datos.test, type="response")
predictor = rep(0, length(pr))
predictor[pr > 0.5] = 1
vector.cv.glm = append(vector.cv.glm, mean(predictor != mpg01.test))
}
paste("Error Medio: ", mean(vector.cv.glm)*100, "%")
library(ISLR)
Predictoras = cbind(Auto$mpg, Auto$displacement, Auto$horsepower, Auto$weight, Auto$year)
colnames(Predictoras) = c("mpg", "displacement", "horsepower", "weight", "year")
set.seed(2)
indices_test = sample(nrow(Predictoras), 2*nrow(Predictoras)%/%10, replace=FALSE)
Predictoras_test = Predictoras[indices_test,]
Predictoras_train = Predictoras[-indices_test,]
mediana_mpg = median(Auto$mpg)
Predictoras_train_mpg01 = data.frame(Predictoras_train,
mpg01=sign(Predictoras_train[,"mpg"] - mediana_mpg))
Predictoras_test_mpg01 = data.frame(Predictoras_test,
mpg01=sign(Predictoras_test[,"mpg"] - mediana_mpg))
for(i in 1:nrow(Predictoras_test_mpg01)){
if((Predictoras_test_mpg01[i,"mpg01"]) == -1)
Predictoras_test_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_train_mpg01)){
if((Predictoras_train_mpg01[i,"mpg01"]) == -1)
Predictoras_train_mpg01[i,"mpg01"] = 0
}
ajuste_rlog <- glm(mpg01 ~ displacement + horsepower + weight + year,
data= Predictoras_train_mpg01, family=binomial)
probabilidades = predict(ajuste_rlog, Predictoras_test_mpg01, type="response")
probabilidades01 = rep(1,dim(Predictoras_test_mpg01)[1])
probabilidades01[probabilidades<0.5] = 0
matriz_confusion = table(probabilidades01, Predictoras_test_mpg01$mpg01)
print(matriz_confusion)
error = (matriz_confusion[1,2] + matriz_confusion[2,1])/sum(matriz_confusion)
print(error)
library(class)
library(e1071)
set.seed(2)
columnas=  dim(Predictoras_train_mpg01)[2]
datos_normalizados = scale(rbind(Predictoras_test_mpg01[,-columnas],
Predictoras_train_mpg01[,-columnas]))
test_normalizada = datos_normalizados[1:dim(Predictoras_test_mpg01)[1],]
train_normalizada = datos_normalizados[(dim(Predictoras_test_mpg01)[1] +1):
dim(datos_normalizados)[1],]
View(datos_normalizados)
View(datos_normalizados)
mpg01 = rep(0, nrow(Auto))
mpg01[mpg > median(mpg)] = 1
Auto2 = data.frame(Auto, mpg01)
View(Auto2)
View(Auto2)
library(ISLR)
Predictoras = cbind(Auto$mpg, Auto$displacement, Auto$horsepower, Auto$weight, Auto$year)
colnames(Predictoras) = c("mpg", "displacement", "horsepower", "weight", "year")
set.seed(2)
indices_test = sample(nrow(Predictoras), 2*nrow(Predictoras)%/%10, replace=FALSE)
Predictoras_test = Predictoras[indices_test,]
Predictoras_train = Predictoras[-indices_test,]
mediana_mpg = median(Auto$mpg)
Predictoras_train_mpg01 = data.frame(Predictoras_train,
mpg01=sign(Predictoras_train[,"mpg"] - mediana_mpg))
Predictoras_test_mpg01 = data.frame(Predictoras_test,
mpg01=sign(Predictoras_test[,"mpg"] - mediana_mpg))
for(i in 1:nrow(Predictoras_test_mpg01)){
if((Predictoras_test_mpg01[i,"mpg01"]) == -1)
Predictoras_test_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_train_mpg01)){
if((Predictoras_train_mpg01[i,"mpg01"]) == -1)
Predictoras_train_mpg01[i,"mpg01"] = 0
}
probabilidades = predict(ajuste_rlog, Predictoras_test_mpg01, type="response")
probabilidades01 = rep(1,dim(Predictoras_test_mpg01)[1])
probabilidades01[probabilidades<0.5] = 0
matriz_confusion = table(probabilidades01, Predictoras_test_mpg01$mpg01)
print(matriz_confusion)
error = (matriz_confusion[1,2] + matriz_confusion[2,1])/sum(matriz_confusion)
print(error)
library(class)
library(e1071)
set.seed(2)
library(ISLR)
Predictoras = cbind(Auto$mpg, Auto$displacement, Auto$horsepower, Auto$weight, Auto$year)
colnames(Predictoras) = c("mpg", "displacement", "horsepower", "weight", "year")
set.seed(2)
indices_test = sample(nrow(Predictoras), 2*nrow(Predictoras)%/%10, replace=FALSE)
Predictoras_test = Predictoras[indices_test,]
Predictoras_train = Predictoras[-indices_test,]
mediana_mpg = median(Auto$mpg)
Predictoras_train_mpg01 = data.frame(Predictoras_train,
mpg01=sign(Predictoras_train[,"mpg"] - mediana_mpg))
Predictoras_test_mpg01 = data.frame(Predictoras_test,
mpg01=sign(Predictoras_test[,"mpg"] - mediana_mpg))
for(i in 1:nrow(Predictoras_test_mpg01)){
if((Predictoras_test_mpg01[i,"mpg01"]) == -1)
Predictoras_test_mpg01[i,"mpg01"] = 0
}
for(i in 1:nrow(Predictoras_train_mpg01)){
if((Predictoras_train_mpg01[i,"mpg01"]) == -1)
Predictoras_train_mpg01[i,"mpg01"] = 0
}
ajuste_rlog <- glm(mpg01 ~ displacement + horsepower + weight + year,
data= Predictoras_train_mpg01, family=binomial)
probabilidades = predict(ajuste_rlog, Predictoras_test_mpg01, type="response")
probabilidades01 = rep(1,dim(Predictoras_test_mpg01)[1])
probabilidades01[probabilidades<0.5] = 0
matriz_confusion = table(probabilidades01, Predictoras_test_mpg01$mpg01)
print(matriz_confusion)
error = (matriz_confusion[1,2] + matriz_confusion[2,1])/sum(matriz_confusion)
print(error)
library(class)
library(e1071)
set.seed(2)
columnas=  dim(Predictoras_train_mpg01)[2]
datos_normalizados = scale(rbind(Predictoras_test_mpg01[,-columnas],
Predictoras_train_mpg01[,-columnas]))
test_normalizada = datos_normalizados[1:dim(Predictoras_test_mpg01)[1],]
train_normalizada = datos_normalizados[(dim(Predictoras_test_mpg01)[1] +1):
dim(datos_normalizados)[1],]
mpg01_train = Predictoras_train_mpg01[,columnas]
mpg01_test = Predictoras_test_mpg01[,columnas]
mpg01_ambos = c(mpg01_train, mpg01_test)
posibles_k <- tune.knn(datos_normalizados, as.factor(mpg01_ambos), k=1:10,
tune_control = tune.control(sampling = "cross"))
summary(posibles_k)
predicciones = knn(train_normalizada, test_normalizada, mpg01_train, k=4)
matriz_confusion_knn = table(predicciones, mpg01_test)
print(matriz_confusion_knn)
errorknn = ((matriz_confusion_knn[1,2] + matriz_confusion_knn[2,1])/sum(matriz_confusion_knn))
print(errorknn)
View(Predictoras)
View(Predictoras)
f = nrow(Auto)
a = round(f*0.8)
train.index=sample(f, a, replace=FALSE)
train = Auto[train.index, ]
test = Auto[-train.index, ]
mpg01 = rep(0, nrow(Auto))
mpg01[mpg > median(mpg)] = 1
Auto2 = data.frame(Auto, mpg01)
Datos.train = Auto2[train.index, ]
Datos.test = Auto2[-train.index, ]
mpg01.test = mpg01[-train.index]
modelo = glm(mpg01~cylinders+weight+displacement+horsepower, data=Auto2, family="binomial", subset=train.index)
pr = predict(modelo, Datos.test, type="response")
prediccion.glm = rep(-1, length(pr))
prediccion.glm[pr > 0.5] = 1
mpg_11 = rep(-1, nrow(Auto))
mpg_11[mpg > median(mpg)] = 1
mpg_11.test = mpg_11[-train.index]
table(prediccion.glm, mpg_11.test)
mean(prediccion.glm != mpg_11.test)
library(class)
train.knn = cbind(cylinders, weight, displacement, horsepower)[train.index, ]
test.knn = cbind(cylinders, weight, displacement, horsepower)[-train.index, ]
mpg01.train = mpg01[train.index]
vector.knn = vector()
for (k in 1:100){
modelo = knn(train.knn, test.knn, mpg01.train, k=k)
vector.knn = append(vector.knn,mean(modelo != mpg01.test))
}
M = matrix(vector.knn,nrow=1,ncol=length(vector.knn),dimnames=list(c("Acierto"), paste("K=", c(1:length(vector.knn)))))
k.optimo = which.min(M)
paste("K test = ",k.optimo)
modelo = knn(train.knn, test.knn, mpg01.train, k=k.optimo)
table(modelo, mpg01.test)
mean(modelo != mpg01.test)
particiones = 5
corte = round(f/particiones)
vector.cv.glm = vector()
for(p in 0:(particiones-1)){
test.index.cv.glm = ((p*corte)+1):(corte*(p+1))
mpg01.test = mpg01[test.index.cv.glm]
Datos.test = Auto2[test.index.cv.glm,]
Datos.train = Auto2[-test.index.cv.glm,]
modelo = glm(mpg01~cylinders+weight+displacement+horsepower, data=Datos.train,
family="binomial")
pr = predict(modelo, Datos.test, type="response")
predictor = rep(0, length(pr))
predictor[pr > 0.5] = 1
vector.cv.glm = append(vector.cv.glm, mean(predictor != mpg01.test))
}
paste("Error Medio: ", mean(vector.cv.glm)*100, "%")
